# Example environment variables for debatesavy

# DATABASE_URL (optional) - not required for the stateless prototype.
# If you enable persistence later, set this to your Postgres connection string.

# Ollama HTTP API host (where your friend's Ollama server is reachable)
# e.g. http://192.168.1.50:11434 or http://localhost:11434
OLLAMA_URL=http://localhost:11434

# Ollama model name to use
OLLAMA_MODEL=llama2

# (Optional) Google Generative AI key removed â€” using Ollama only

# App environment
NODE_ENV=development
PORT=3000

# Session / auth secret (used for signing tokens/cookies)
SESSION_SECRET=replace_with_a_strong_random_value

# Public backend URL for frontend to call (set on frontend host if needed)
NEXT_PUBLIC_BACKEND_URL=http://localhost:3000

# (Optional) Additional tuning
# (Optional) Additional tuning for Ollama calls
# Maximum tokens returned by the model
# MAX_AI_RESPONSE_TOKENS=512
# Timeout in milliseconds for Ollama requests (default 15000)
OLLAMA_TIMEOUT_MS=15000
# Number of times to retry on transient failures (default 2)
OLLAMA_MAX_RETRIES=2
# Base backoff in ms used for exponential retry (default 500)
OLLAMA_BACKOFF_MS=500

# Summary endpoint rate-limiting and validation (prototype defaults)
# Number of requests allowed per user within window
SUMMARY_RATE_LIMIT_REQS=10
# Window in milliseconds (default 60000 = 1 minute)
SUMMARY_RATE_LIMIT_WINDOW_MS=60000
# Max messages accepted in a single payload
SUMMARY_MAX_MESSAGES=200
# Max author name length
SUMMARY_MAX_AUTHOR_LEN=64
# Max single message content length
SUMMARY_MAX_CONTENT_LEN=5000
# Max total characters across messages
SUMMARY_MAX_TOTAL_CHARS=30000
